{"cells":[{"cell_type":"markdown","metadata":{"id":"uvby0xnlSYgL"},"source":["# OpenAI's Whisper\n","\n","Whisper is an **A**utomatic **S**peech **R**ecognition (ASR) model from OpenAI. We use it to extract highly accurate text from YouTube videos."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"Ub_9-TNJSYgO","executionInfo":{"status":"ok","timestamp":1678113181029,"user_tz":-60,"elapsed":25303,"user":{"displayName":"Karlo Timmerman","userId":"16606459874544646181"}},"outputId":"39926296-ecc3-4938-d1ca-4de1a36c72b8","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/openai/whisper.git\n","  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-5au75bfp\n","  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-5au75bfp\n","  Resolved https://github.com/openai/whisper.git to commit 3e1780fd37686666f568be9c99f5b5e3e4f2eb92\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (1.22.4)\n","Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (1.13.1+cu116)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (4.64.1)\n","Requirement already satisfied: more-itertools in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (9.1.0)\n","Collecting transformers>=4.19.0\n","  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ffmpeg-python==0.2.0\n","  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n","Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from ffmpeg-python==0.2.0->openai-whisper==20230124) (0.16.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (2.25.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (2022.6.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (6.0)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (3.9.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (23.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->openai-whisper==20230124) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (1.26.14)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (2022.12.7)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (4.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (2.10)\n","Building wheels for collected packages: openai-whisper\n","  Building wheel for openai-whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for openai-whisper: filename=openai_whisper-20230124-py3-none-any.whl size=1179407 sha256=13887b36f1e338f3b4511d6c391f46de86d3c5b1c070b2d4c9016fa260a1d0ff\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-shmjlqqr/wheels/a7/70/18/b7693c07b1d18b3dafb328f5d0496aa0d41a9c09ef332fd8e6\n","Successfully built openai-whisper\n","Installing collected packages: tokenizers, ffmpeg-python, huggingface-hub, transformers, openai-whisper\n","Successfully installed ffmpeg-python-0.2.0 huggingface-hub-0.12.1 openai-whisper-20230124 tokenizers-0.13.2 transformers-4.26.1\n","Get:1 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n","Get:2 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n","Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  InRelease\n","Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n","Get:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease [18.1 kB]\n","Hit:6 http://archive.ubuntu.com/ubuntu focal InRelease\n","Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  Release\n","Get:8 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n","Hit:9 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n","Get:10 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,535 kB]\n","Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n","Get:12 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n","Get:13 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1,013 kB]\n","Hit:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n","Hit:15 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n","Get:17 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main Sources [2,396 kB]\n","Get:18 http://archive.ubuntu.com/ubuntu focal-updates/multiverse amd64 Packages [31.2 kB]\n","Get:19 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3,014 kB]\n","Get:20 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [2,134 kB]\n","Get:21 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,307 kB]\n","Get:22 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main amd64 Packages [1,136 kB]\n","Fetched 13.9 MB in 3s (4,529 kB/s)\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","25 packages can be upgraded. Run 'apt list --upgradable' to see them.\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","ffmpeg is already the newest version (7:4.2.7-0ubuntu0.1).\n","0 upgraded, 0 newly installed, 0 to remove and 25 not upgraded.\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","\u001b[1;31mE: \u001b[0mUnable to locate package pydub\u001b[0m\n","\u001b[1;31mE: \u001b[0mUnable to locate package AudioSegment\u001b[0m\n"]}],"source":["!pip install git+https://github.com/openai/whisper.git\n","!sudo apt update -y && sudo apt install ffmpeg -y\n","!sudo apt install -y pydub AudioSegment\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"VntUTIsuSYgP","outputId":"0a5a584d-c749-495f-f689-1b0a0137ef63","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678113302543,"user_tz":-60,"elapsed":106542,"user":{"displayName":"Karlo Timmerman","userId":"16606459874544646181"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/jax/__init__.py:177: UserWarning: The jax module appears to have been reloaded within the python process. This is not well-supported and can cause unpredictable side-effects. For information see https://github.com/google/jax/issues/13857.\n","  _warn(\"The jax module appears to have been reloaded within the python process. \"\n"]},{"output_type":"stream","name":"stdout","text":["cpu\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████████████████████████████| 2.87G/2.87G [00:59<00:00, 52.2MiB/s]\n"]}],"source":["import whisper\n","import torch  # pytorch install steps: pytorch.org\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(device)\n","\n","model = whisper.load_model(\"large\").to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"B5ex2ub3SYgP"},"outputs":[],"source":["from datasets import load_dataset\n","\n","videos_meta = load_dataset(\n","    \"jamescalam/channel-metadata\",\n","    split=\"train\"\n",")\n","videos_meta"]},{"cell_type":"markdown","metadata":{"id":"snKawNGJSYgQ"},"source":["Create videos metadata dictionary..."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"p51gkHMrSYgQ","colab":{"base_uri":"https://localhost:8080/","height":246},"executionInfo":{"status":"error","timestamp":1678113088469,"user_tz":-60,"elapsed":4,"user":{"displayName":"Karlo Timmerman","userId":"16606459874544646181"}},"outputId":"41ad2355-71f5-48f0-ffd1-8c67a4bc6cc9"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-6614f64d833b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvideos_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvideos_meta\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m# create entry in dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     videos_dict[row['Video ID']] = {\n","\u001b[0;31mNameError\u001b[0m: name 'videos_meta' is not defined"]}],"source":["\n","    }"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"qsNc913JSYgQ","outputId":"8eb76d84-7f2f-497a-da1b-cfc559d8ecf9","colab":{"base_uri":"https://localhost:8080/","height":228},"executionInfo":{"status":"error","timestamp":1678113083819,"user_tz":-60,"elapsed":620,"user":{"displayName":"Karlo Timmerman","userId":"16606459874544646181"}}},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-0f1cf5427c91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# get list of MP3 audio files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./mp3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'*.mp3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'Path' is not defined"]}],"source":["# get list of MP3 audio files\n","paths = [str(x) for x in Path('./mp3').glob('*.mp3')]\n","print(len(paths))\n","print(paths[:5])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y2rlCNhaSYgR","outputId":"1c1a1a01-cbe3-4168-e646-36ce5769b743"},"outputs":[{"data":{"text/plain":["'35Pdoyi6ZoQ'"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# we get the IDs like so\n","paths[0].split('/')[-1][:-4]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kFR3MZtaSYgR"},"outputs":[],"source":["data = []\n","for i, path in enumerate(tqdm(paths)):\n","    _id = path.split('/')[-1][:-4]\n","    # transcribe to get speech-to-text data\n","    result = model.transcribe(path)\n","    # add results to data list\n","    data.extend(result['segments'])"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"08obYyahSYgR","outputId":"22fadb9b-0252-4f21-a92d-317d9eb01869"},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/108 [00:00<?, ?it/s]2022-10-13 10:56:36.068291: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","100%|██████████| 108/108 [7:10:39<00:00, 239.26s/it] \n"]},{"data":{"text/plain":["27214"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["from pathlib import Path\n","from tqdm.auto import tqdm\n","import json\n","\n","# set window (length of text chunk) and stride\n","window = 1\n","stride = 1  # smaller stride creates overlap\n","\n","data = []\n","\n","results = []\n","with open(\"transcription.jsonl\", \"w\", encoding=\"utf-8\") as fp:\n","    for i, path in enumerate(tqdm(paths)):\n","        _id = path.split('/')[-1][:-4]\n","        # transcribe to get speech-to-text data\n","        result = model.transcribe(path)\n","        segments = result['segments']\n","        # get the video metadata...\n","        video_meta = videos_dict[_id]\n","        for j in range(0, len(segments), stride):\n","            j_end = min(j+window, len(segments)-1)\n","            text = ''.join([x[\"text\"] for x in segments[j:j_end]])\n","            start = segments[j]['start']\n","            end = segments[j_end]['end']\n","            row_id = f\"{_id}-t{segments[j]['start']}\"\n","            meta = {\n","                **video_meta,\n","                **{\n","                    \"id\": row_id,\n","                    \"text\": text.strip(),\n","                    \"start\": start,\n","                    \"end\": end\n","                }\n","            }\n","            data.append(meta)\n","            json.dump(meta, fp)\n","            fp.write('\\n')\n","\n","len(data)"]},{"cell_type":"markdown","metadata":{"tags":[],"id":"CauQw1MxSYgS"},"source":["---\n","\n","## Append more to dataset without overwriting/redoing\n","\n","First check what we already have"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fh0w9st_SYgS","outputId":"b26bbf2f-aa48-4d52-f52a-f9f63804b5e1"},"outputs":[{"data":{"text/plain":["108"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import json\n","\n","existing_ids = []\n","\n","with open(\"transcription.jsonl\", 'r', encoding='utf-8') as fp:\n","    for line in fp:\n","        obj = json.loads(line)\n","        existing_ids.append(obj['url'].split('/')[-1])\n","\n","existing_ids = set(existing_ids)\n","len(existing_ids)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CTaKNorWSYgS","outputId":"f313177d-dd6e-4b22-c3ec-0d37a3ad34f0"},"outputs":[{"data":{"text/plain":["['gVAJ_l_S7uQ', '1gN1snKBLP0', 'YvVQgvAz9dY', '3Wqh4iUupbM', 'jjQetJtQDS4']"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["list(existing_ids)[:5]"]},{"cell_type":"markdown","metadata":{"id":"_TXrI_0mSYgT"},"source":["Get paths to videos not already in `existing_ids`..."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R2E3iwQFSYgT","executionInfo":{"status":"error","timestamp":1678113023030,"user_tz":-60,"elapsed":622,"user":{"displayName":"","userId":""}},"outputId":"91871ca7-4bfd-4b03-8953-665bdccc3fc4","colab":{"base_uri":"https://localhost:8080/","height":391}},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-376b8dbfabf2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpydub\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAudioSegment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpydub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayback\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# load the audio file and play it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0maudio_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAudioSegment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"somewhere_over_the_rainbow.mp3\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mp3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pydub'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["# load the audio file and play it\n","audio_file = AudioSegment.from_file(\"somewhere_over_the_rainbow.mp3\", format=\"mp3\")\n","play(audio_file)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cyB-fT5FSYgT","outputId":"e1ed710d-bacf-4b75-aa46-d80a623a039a"},"outputs":[{"name":"stdout","output_type":"stream","text":["0\n","[]\n"]}],"source":["paths = [x for x in paths if x.split('/')[-1][:-4] not in existing_ids]\n","print(len(paths))\n","print(paths[:5])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RKvT8xr_SYgT"},"outputs":[],"source":["from pathlib import Path\n","from tqdm.auto import tqdm\n","import json\n","\n","# set window (length of text chunk) and stride\n","window = 1\n","stride = 1  # smaller stride creates overlap\n","\n","results = []\n","with open(\"transcription.jsonl\", \"a\", encoding=\"utf-8\") as fp:\n","    for i, path in enumerate(tqdm(paths)):\n","        _id = path.split('/')[-1][:-4]\n","        # transcribe to get speech-to-text data\n","        result = model.transcribe(path)\n","        segments = result['segments']\n","        # get the video metadata...\n","        video_meta = videos_dict[_id]\n","        for j in range(0, len(segments), stride):\n","            j_end = min(j+window, len(segments)-1)\n","            text = ''.join([x[\"text\"] for x in segments[j:j_end]])\n","            start = segments[j]['start']\n","            end = segments[j_end]['end']\n","            _id = f\"{_id}-t{segments[j]['start']}\"\n","            meta = {\n","                **video_meta,\n","                **{\n","                    \"id\": _id,\n","                    \"text\": text.strip(),\n","                    \"start\": start,\n","                    \"end\": end\n","                }\n","            }\n","            json.dump(meta, fp)\n","            fp.write('\\n')\n","\n","len(data)"]}],"metadata":{"environment":{"kernel":"python3","name":"common-cu110.m95","type":"gcloud","uri":"gcr.io/deeplearning-platform-release/base-cu110:m95"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"vscode":{"interpreter":{"hash":"b8e7999f96e1b425e2d542f21b571f5a4be3e97158b0b46ea1b2500df63956ce"}},"colab":{"provenance":[{"file_id":"https://github.com/jamescalam/ask-youtube/blob/main/youtube-search/01-openai-whisper.ipynb","timestamp":1678113057477}]}},"nbformat":4,"nbformat_minor":0}